{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd09058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as scp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score,classification_report,make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectKBest,SelectFpr\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa36b83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1    0.933418\n",
      " 1    0.066582\n",
      "Name: Pass/Fail, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_main = pd.read_csv('Ultrasound_1.csv')\n",
    "df = deepcopy(df_main)\n",
    "print(df['Pass/Fail'].value_counts()/df.shape[0])\n",
    "y = df.pop('Pass/Fail').values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee326906",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processing_Df:\n",
    "    def __init__(self,df_lcl):\n",
    "        self.df_cl = df_lcl\n",
    "        self.lst_fl = []\n",
    "        self.lst_int = []\n",
    "        self.lst_o = []\n",
    "        self.stats_lst = []\n",
    "        self.lst_d_m_c = []\n",
    "        \n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    def df_num(self):\n",
    "        #self.df_cl = self.Drop_mis_column()\n",
    "        for cols in self.df_cl:\n",
    "            if self.df_cl[cols].dtypes == 'float':\n",
    "                self.lst_fl.append(cols)\n",
    "            if self.df_cl[cols].dtypes == 'int':\n",
    "                self.lst_int.append(cols)\n",
    "            if self.df_cl[cols].dtypes == 'object':\n",
    "                self.lst_o.append(cols)    \n",
    "            \n",
    "        return (self.lst_fl,self.lst_int,self.lst_o)\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    def df_std_removal(self):\n",
    "        \n",
    "        df_stats = self.df_cl.describe()\n",
    "        for i in df_stats.columns:\n",
    "            if df_stats.loc['std',i] == 0:\n",
    "                self.stats_lst.append(i)\n",
    "        self.df_cl.drop(columns=self.stats_lst,inplace=True) \n",
    "        return (self.df_cl)\n",
    "#-------------------------------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "    def Drop_mis_column(self):\n",
    "        dct_df = {cols:(self.df_cl[cols].isnull().sum()/self.df_cl.shape[0])*100 for cols in df.columns}\n",
    "        for j in dct_df.keys():\n",
    "            if dct_df[j] > 25.0:\n",
    "                self.lst_d_m_c.append(j)\n",
    "        self.df_cl.drop(columns=self.lst_d_m_c,inplace=True)\n",
    "        return (self.df_cl)\n",
    "#&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "    def Standardisation(self):\n",
    "        tmp = []\n",
    "        for i in  self.df_cl.columns:\n",
    "            if self.df_cl[i].max()>3:\n",
    "                tmp.append(i)\n",
    "            else:  \n",
    "                continue\n",
    "        std_sc = StandardScaler()\n",
    "        self.df_cl[tmp] = std_sc.fit_transform( self.df_cl[tmp])\n",
    "        return  self.df_cl\n",
    "#-----------------------><><><><><><><><<><>-------------------------------------------------------------\n",
    "    def Mis_Treat(self):\n",
    "        for i in self.df_cl.columns:\n",
    "            if self.df_cl[i].isnull().sum() != 0:\n",
    "                if (self.df_cl[i].skew() > 1) | (self.df_cl[i].skew() < -1):\n",
    "                    self.df_cl[i].fillna(value=self.df_cl[i].median(),inplace=True)\n",
    "                elif (self.df_cl[i].skew() < 1) | (self.df_cl[i].skew() > -1):\n",
    "                     self.df_cl[i].fillna(value=self.df_cl[i].mean(),inplace=True)\n",
    "        return self.df_cl\n",
    "#--------------------------->>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<------------------------------------------\n",
    "    def Replacing_outliers(self,tmp):\n",
    "        df_tmp_zscore = scp.stats.zscore(self.df_cl)\n",
    "        \n",
    "        for i in df_tmp_zscore.columns:\n",
    "            if tmp > 0:\n",
    "                if (df_tmp_zscore[i]>tmp).any():\n",
    "                    arr1 = np.where(df_tmp_zscore[i]>tmp)\n",
    "                    \n",
    "                    tmp1 = tmp*self.df_cl[i].std() + self.df_cl[i].mean()\n",
    "                    for j in arr1[0]:\n",
    "                        self.df_cl.loc[j,i] =  tmp1\n",
    "            else:\n",
    "                if (df_tmp_zscore[i]<tmp).any():\n",
    "                    arr1 = np.where(df_tmp_zscore[i]<tmp)\n",
    "                   \n",
    "                    tmp1 = -tmp*self.df_cl[i].std() + self.df_cl[i].mean()\n",
    "                    for j in arr1[0]:\n",
    "                        \n",
    "                        self.df_cl.loc[j,i] =  tmp1\n",
    "        return self.df_cl\n",
    "#-------------------------><><><><MAIN><MAIN><><><><><><><>><><><><><><><><---------------------------------------------    def         \n",
    "    def main(self):\n",
    "        self.Drop_mis_column()\n",
    "        self.df_std_removal()\n",
    "        self.df_cl = self.Mis_Treat()\n",
    "        self.Replacing_outliers(3.0)\n",
    "        self.Replacing_outliers(-3.0)\n",
    "        self.Standardisation()\n",
    "        return self.df_cl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd95f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "585    0\n",
       "586    0\n",
       "587    0\n",
       "588    0\n",
       "589    0\n",
       "Length: 440, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_o = Processing_Df(df)\n",
    "l_f,l_int,l_o = df_o.df_num()\n",
    "df_new  =  df_o.main()\n",
    "df_new.isnull().sum()\n",
    "#sns.scatterplot(data = df_new,x = range(df.shape[0]),y = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58d0a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_new\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "df_t = X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f032485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr=LogisticRegression(C = 0.1, random_state = 42, solver = 'liblinear')\n",
    "dt=DecisionTreeClassifier()\n",
    "rf=RandomForestClassifier()\n",
    "sel_feat = SelectFpr() \n",
    "# gnb=GaussianNB()\n",
    "# knn = KNeighborsClassifier(n_neighbors=3)\n",
    "# svm = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e3973",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_grid = [{'feat' : [sel_feat],\n",
    "                    'feat__alpha' : [0.1,0.08,0.05,0.02]\n",
    "                    },\n",
    "                   {'classifier' : [dt],\n",
    "                   'classifier__max_depth' : [5,15,3],\n",
    "                   'classifier__criterion' : ['gini' , 'entropy'],\n",
    "                   #'max_features' : ['log2' , 'sqrt']\n",
    "                  },\n",
    "                  \n",
    "                  { 'classifier' : [rf],\n",
    "                    'classifier__n_estimators' : [50,500,50],\n",
    "                    'classifier__max_depth' : [5,15,3],\n",
    "                   'classifier__criterion' : ['gini' , 'entropy'],\n",
    "                   #'max_features' : ['log2' , 'sqrt']\n",
    "                  }]\n",
    "ppln = Pipeline([('feat',sel_feat),('classifier',dt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e044bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hy_tun = GridSearchCV(ppln, param_grid=parameters_grid, cv = 5, \n",
    "                            scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "                                       're_call': 'recall'},refit='re_call')\n",
    "model_hy_tun.fit(X_train,y_train)\n",
    "print(model_hy_tun.best_score_)\n",
    "print(model_hy_tun.best_params_)\n",
    "print(model_hy_tun.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d1df0e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31677/2091127585.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e737851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
