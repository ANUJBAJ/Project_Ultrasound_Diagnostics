{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "69f985ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as scp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score,classification_report,make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectKBest,SelectFpr\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d92dea4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1    0.933418\n",
      " 1    0.066582\n",
      "Name: Pass/Fail, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_main = pd.read_csv('Ultrasound_1.csv')\n",
    "df = deepcopy(df_main)\n",
    "print(df['Pass/Fail'].value_counts()/df.shape[0])\n",
    "y = df.pop('Pass/Fail').values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "69bcf7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processing_Df:\n",
    "    def __init__(self,df_lcl):\n",
    "        self.df_cl = df_lcl\n",
    "        self.lst_fl = []\n",
    "        self.lst_int = []\n",
    "        self.lst_o = []\n",
    "        self.stats_lst = []\n",
    "        self.lst_d_m_c = []\n",
    "        \n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    def df_num(self):\n",
    "        #self.df_cl = self.Drop_mis_column()\n",
    "        for cols in self.df_cl:\n",
    "            if self.df_cl[cols].dtypes == 'float':\n",
    "                self.lst_fl.append(cols)\n",
    "            if self.df_cl[cols].dtypes == 'int':\n",
    "                self.lst_int.append(cols)\n",
    "            if self.df_cl[cols].dtypes == 'object':\n",
    "                self.lst_o.append(cols)    \n",
    "            \n",
    "        return (self.lst_fl,self.lst_int,self.lst_o)\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    def df_std_removal(self):\n",
    "        \n",
    "        df_stats = self.df_cl.describe()\n",
    "        for i in df_stats.columns:\n",
    "            if df_stats.loc['std',i] == 0:\n",
    "                self.stats_lst.append(i)\n",
    "        self.df_cl.drop(columns=self.stats_lst,inplace=True) \n",
    "        return (self.df_cl)\n",
    "#-------------------------------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "    def Drop_mis_column(self):\n",
    "        dct_df = {cols:(self.df_cl[cols].isnull().sum()/self.df_cl.shape[0])*100 for cols in df.columns}\n",
    "        for j in dct_df.keys():\n",
    "            if dct_df[j] > 25.0:\n",
    "                self.lst_d_m_c.append(j)\n",
    "        self.df_cl.drop(columns=self.lst_d_m_c,inplace=True)\n",
    "        return (self.df_cl)\n",
    "#&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "    def Standardisation(self):\n",
    "        tmp = []\n",
    "        for i in  self.df_cl.columns:\n",
    "            if self.df_cl[i].max()>3:\n",
    "                tmp.append(i)\n",
    "            else:  \n",
    "                continue\n",
    "        std_sc = StandardScaler()\n",
    "        self.df_cl[tmp] = std_sc.fit_transform( self.df_cl[tmp])\n",
    "        return  self.df_cl\n",
    "#-----------------------><><><><><><><><<><>-------------------------------------------------------------\n",
    "    def Mis_Treat(self):\n",
    "        for i in self.df_cl.columns:\n",
    "            if self.df_cl[i].isnull().sum() != 0:\n",
    "                if (self.df_cl[i].skew() > 1) | (self.df_cl[i].skew() < -1):\n",
    "                    self.df_cl[i].fillna(value=self.df_cl[i].median(),inplace=True)\n",
    "                elif (self.df_cl[i].skew() < 1) | (self.df_cl[i].skew() > -1):\n",
    "                     self.df_cl[i].fillna(value=self.df_cl[i].mean(),inplace=True)\n",
    "        return self.df_cl\n",
    "#--------------------------->>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<------------------------------------------\n",
    "    def Replacing_outliers(self,tmp):\n",
    "        df_tmp_zscore = scp.stats.zscore(self.df_cl)\n",
    "        \n",
    "        for i in df_tmp_zscore.columns:\n",
    "            if tmp > 0:\n",
    "                if (df_tmp_zscore[i]>tmp).any():\n",
    "                    arr1 = np.where(df_tmp_zscore[i]>tmp)\n",
    "                    \n",
    "                    tmp1 = tmp*self.df_cl[i].std() + self.df_cl[i].mean()\n",
    "                    for j in arr1[0]:\n",
    "                        self.df_cl.loc[j,i] =  tmp1\n",
    "            else:\n",
    "                if (df_tmp_zscore[i]<tmp).any():\n",
    "                    arr1 = np.where(df_tmp_zscore[i]<tmp)\n",
    "                   \n",
    "                    tmp1 = -tmp*self.df_cl[i].std() + self.df_cl[i].mean()\n",
    "                    for j in arr1[0]:\n",
    "                        \n",
    "                        self.df_cl.loc[j,i] =  tmp1\n",
    "        return self.df_cl\n",
    "#-------------------------><><><><MAIN><MAIN><><><><><><><>><><><><><><><><---------------------------------------------    def         \n",
    "    def main(self):\n",
    "        self.Drop_mis_column()\n",
    "        self.df_std_removal()\n",
    "        self.df_cl = self.Mis_Treat()\n",
    "        self.Replacing_outliers(3.0)\n",
    "        self.Replacing_outliers(-3.0)\n",
    "        self.Standardisation()\n",
    "        return self.df_cl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3002bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_o = Processing_Df(df)\n",
    "l_f,l_int,l_o = df_o.df_num()\n",
    "df_new  =  df_o.main()\n",
    "\n",
    "#sns.scatterplot(data = df_new,x = range(df.shape[0]),y = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7cb833db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = SelectFpr(alpha = 0.02).fit_transform(df_new,y)\n",
    "# df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eb9484e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in df.columns:\n",
    "#     if df[i].isnull().sum() != 0:\n",
    "#         if (df[i].skew() > 1) | (df[i].skew() < -1):\n",
    "#             df[i].fillna(value=df[i].median(),inplace=True)\n",
    "#         elif (df[i].skew() < 1) | (df[i].skew() > -1):\n",
    "#             df[i].fillna(value=df[i].mean(),inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d0378b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Replacing_outliers(df_tmp,tmp):\n",
    "#     df_tmp_zscore = scp.stats.zscore(df_tmp)\n",
    "#     for i in df_tmp_zscore.columns:\n",
    "#         if tmp > 0:\n",
    "#             if (df_tmp_zscore[i]>tmp).any():\n",
    "#                 arr1 = np.where(df_tmp_zscore[i]>tmp)\n",
    "#                 #print((len(arr1[0])/df_tmp.shape[0])*100)\n",
    "#                 tmp1 = tmp*df_tmp[i].std() + df_tmp[i].mean()\n",
    "#         else :\n",
    "#             if (df_tmp_zscore[i]<tmp).any():\n",
    "#                 arr1 = np.where(df_tmp_zscore[i]<tmp)\n",
    "#                 tmp1 = -tmp*df_tmp[i].std() + df_tmp[i].mean()\n",
    "#     for j in arr1[0]:\n",
    "#         df_tmp.loc[j,i] =  tmp1\n",
    "#     return df_tmp\n",
    "       \n",
    "    \n",
    "# df_new = Replacing_outliers(df_new,3)\n",
    "# df_new = Replacing_outliers(df_new,-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "05b962e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1577, 261)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad = df_new.corr().abs()\n",
    "dct_1 = {j : k for j,k in enumerate(df_new.columns)}\n",
    "upper = ad.where(np.triu(np.ones(ad.shape), k=1).astype(bool))\n",
    "threshold = 0.9  # Set your threshold value\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "df_new.drop(columns=to_drop,inplace  = True)\n",
    "df_new.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for  cols in ad.columns:\n",
    "#              cmp = np.where((ad[cols] >0.98) | (ad[cols] <-0.98))[0]\n",
    "    \n",
    "#              if len(cmp) > 1:\n",
    "#                 for val in cmp:\n",
    "#                     lst_corr.append(dct_1[val])\n",
    "   \n",
    "#         lst_corr = list(set(lst_corr))\n",
    "#         self.df_cl.drop(columns = lst_corr,inplace =True)\n",
    "#         return self.df_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9eaffac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1577, 261)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ef793a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_new\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa664b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr=LogisticRegression(C = 0.1, random_state = 42, solver = 'liblinear')\n",
    "dt=DecisionTreeClassifier()\n",
    "rf=RandomForestClassifier()\n",
    "sel_feat =SelectFpr() \n",
    "# gnb=GaussianNB()\n",
    "# knn = KNeighborsClassifier(n_neighbors=3)\n",
    "# svm = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f872da01",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_grid = [{'feat' : [sel_feat],\n",
    "                    'feat__alpha' : [0.1,0.08,0.05,0.02],\n",
    "                     \n",
    "                    },\n",
    "                   {'classifier' : [dt],\n",
    "                   \n",
    "                    'classifier__max_depth' : [5,15,3],\n",
    "                   'classifier__criterion' : ['gini' , 'entropy'],\n",
    "                   #'max_features' : ['log2' , 'sqrt']\n",
    "                  },\n",
    "                  \n",
    "                  { 'classifier' : [rf],\n",
    "                    'classifier__n_estimators' : [50,500,50],\n",
    "                    'classifier__max_depth' : [5,15,3],\n",
    "                   'classifier__criterion' : ['gini' , 'entropy'],\n",
    "                   #'max_features' : ['log2' , 'sqrt']\n",
    "                  }]\n",
    "ppln = Pipeline([('feat',sel_feat),('classifier',dt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e57f0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23157894736842105\n",
      "{'feat': SelectFpr(), 'feat__alpha': 0.05}\n",
      "Pipeline(steps=[('feat', SelectFpr()),\n",
      "                ('classifier', DecisionTreeClassifier())])\n"
     ]
    }
   ],
   "source": [
    "model_hy_tun = GridSearchCV(ppln, param_grid=parameters_grid, cv = 5, \n",
    "                            scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "                                       're_call': 'recall'},refit='re_call')\n",
    "model_hy_tun.fit(X_train,y_train)\n",
    "print(model_hy_tun.best_score_)\n",
    "print(model_hy_tun.best_params_)\n",
    "print(model_hy_tun.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0989b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_grid = { 'n_estimators' : np.arange(50,500,50),\n",
    "#                     'max_depth' : np.arange(5,15,3),\n",
    "#                    'criterion' : ['gini' , 'entropy'],\n",
    "#                    #'max_features' : ['log2' , 'sqrt']\n",
    "#                   }\n",
    "# model_hy_tun = RandomizedSearchCV(estimator=rf, param_distributions=parameters_grid, cv = 5, n_iter = 30,\n",
    "#                             scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "#                                        're_call': 'recall'},refit='re_call')\n",
    "# model_hy_tun.fit(X_train,y_train)\n",
    "# print(model_hy_tun.best_score_)\n",
    "# print(model_hy_tun.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e51f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_metric = {}\n",
    "# for a,b in zip([lr,dt,knn,svm,rm,gnb],[\"Logistic Regression\",\"Decision Tree\",\"KNN\",\"SVM\",\"Random Forest\",\"Naive Bayes\"]):\n",
    "#     a.fit(X_train,y_train)\n",
    "#     y_pred=a.predict(X_train)\n",
    "#     r_c = recall_score(y_train,y_pred)\n",
    "#     p_c = precision_score(y_train,y_pred)\n",
    "#     f1 = f1_score(y_train,y_pred)\n",
    "#     eval_metric[a] = (r_c,p_c,f1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a7e178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce90f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba9250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
